{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Machine Learning and Kaggle: Titanic \n",
    "\n",
    "#In the Titanic we were given a test data set and using decision trees and sklearn I was able to compute a percentage \n",
    "#of which people would die or survive. I did this by reading in the test data and train data.\n",
    "#I then began to seperate the entities into a table by specific attributes such as the name, ticket, and cabin for the \n",
    "#passengers aboard on the titanic. Then I dropped any information that was not available.\n",
    "#Once I dropped the information that I did not need and was unavailable, I then began to fill in the missing values\n",
    "#for the ages to have some values in this position. I filled in the missing values with the median of all the \n",
    "#titanic data provided to me. Once I completed filling in the table I cross validated the data with the test\n",
    "#and train data using sklearn. From that I was able to generate a percentage of the amount of correct data\n",
    "#I had compared to the train data. Then I compared my results to the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import string\n",
    "import os\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_test = [train, test]\n",
    "train.shape\n",
    "\n",
    "train.head()\n",
    "\n",
    "train.describe()\n",
    "\n",
    "cols = ['Name','Ticket','Cabin']\n",
    "train = train.drop(cols,axis=1)\n",
    "\n",
    "train.head()\n",
    "\n",
    "train = train.dropna()\n",
    "\n",
    "titanic_ds = pd.concat(ds, axis=1)\n",
    "\n",
    "train = pd.concat((train,titanic_ds),axis=1)\n",
    "\n",
    "train = train.drop(['Pclass','Sex','Embarked'],axis=1)\n",
    "\n",
    "train['Age'].fillna(train['Age'].median(), inplace=True)\n",
    "\n",
    "X = train.values\n",
    "y = train['Survived'].values\n",
    "\n",
    "X = np.delete(X,1,axis=1)\n",
    "\n",
    "from sklearn import cross_validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.40,random_state=0)\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "\n",
    "test['Survived'] = 0\n",
    "test.loc[test['Sex'] == 'female','Survived'] = 1\n",
    "data_to_submit = pd.DataFrame({\n",
    "    'PassengerId':test['PassengerId'],\n",
    "    'Survived':test['Survived']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maching Learning and Kaggle: Digit Recognition\n",
    "\n",
    "# Using sklearn, decomposition and linear discriminant analysis I was able to generate a percentage of \n",
    "# correct data from the Digit Recognition competition from Kaggle. I first began reading in the train data.\n",
    "# I then began to display the data given and began to plot a whole slice of the pictures. During this time \n",
    "# I also began to plot the numbers that were displayed in a row by seperating the label and the pixels. \n",
    "# I then began to drop the labels because they were not needed and I split up the data for the model selection.\n",
    "# Once this was completeed I used the principal component analysis for the linear dimensionality reduction.\n",
    "# From this point I was able to transform my data sets using the dataFrame and using plotting a whole slice of pictures\n",
    "# At this point I was able to extract the best score and best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import math\n",
    "\n",
    "# Plots image which is displayed in a row\n",
    "def plot_num(row, w=28, h=28, labels=True):\n",
    "    if labels:\n",
    "        # first column is the label\n",
    "        label = row[0]\n",
    "        # all other columns are pixels\n",
    "        pixels = row[1:]\n",
    "    else:\n",
    "        label = ''\n",
    "        # all other columns are pixels\n",
    "        pixels = row[0:]\n",
    "        \n",
    "\n",
    "    # Creating array of 8-bits pixels from the columns\n",
    "    # 1D array of length 784\n",
    "    # The pixel intensity values are integers from 0 to 255\n",
    "    pixels = 200-np.array(pixels, dtype='uint8')\n",
    "\n",
    "    # Reshaping array into 2D, 28 x 28 array\n",
    "    pixels = pixels.reshape((w, h))\n",
    "\n",
    "    # Plot\n",
    "    if labels:\n",
    "        plt.title('Label is {label}'.format(label=label))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "\n",
    "# Plotting a whole slice of pictures\n",
    "def plot_slice(rows, size_w=28, size_h=28, labels=True):\n",
    "    num = rows.shape[0]\n",
    "    w = 4\n",
    "    h = math.ceil(num / w)\n",
    "    fig, plots = plt.subplots(h, w)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for n in range(0, num):\n",
    "        s = plt.subplot(h, w, n+1)\n",
    "        s.set_xticks(())\n",
    "        s.set_yticks(())\n",
    "        plot_num(rows.ix[n], size_w, size_h, labels)\n",
    "    plt.show()\n",
    "\n",
    "#reading in train data\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "\n",
    "#displaying data\n",
    "print(train.shape)\n",
    "train.sample(5)\n",
    "\n",
    "train.describe()\n",
    "\n",
    "train.info()\n",
    "\n",
    "\n",
    "\n",
    "# Plotting first few rows\n",
    "plot_slice(train[0:12])\n",
    "\n",
    "#dropping labels\n",
    "X_train = train.drop(['label'], axis='columns', inplace=False)\n",
    "y_train = train['label']\n",
    "\n",
    "#using sklearn to split data for model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X_train, y_train, test_size=0.30, random_state=4)\n",
    "\n",
    "\n",
    "#using decompisition from sklearn for randomization\n",
    "n_components = 16\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "#transforming data from train set\n",
    "X_train_pca = pca.transform(X_train)\n",
    "\n",
    "\n",
    "plt.hist(pca.explained_variance_ratio_, bins=n_components, log=True)\n",
    "pca.explained_variance_ratio_.sum()\n",
    "\n",
    "\n",
    "plot_slice(pd.DataFrame(data=X_train_pca[0:12]), size_w=4, size_h=4, labels=False)\n",
    "\n",
    "\n",
    "param_grid = { \"C\" : [0.1]\n",
    "              , \"gamma\" : [0.1]}\n",
    "rf = SVC()\n",
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=2, n_jobs=-1, verbose=1)\n",
    "gs = gs.fit(X_train_pca, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "bp = gs.best_params_\n",
    "\n",
    "t0 = time()\n",
    "clf = SVC(C=bp['C'], kernel='rbf', gamma=bp['gamma'])\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "clf.score(pca.transform(X_ts), y_ts)\n",
    "\n",
    "\n",
    "val = pd.read_csv('../input/test.csv')\n",
    "pred = clf.predict(pca.transform(val))\n",
    "# ImageId,Label\n",
    "\n",
    "val['Label'] = pd.Series(pred)\n",
    "val['ImageId'] = val.index +1\n",
    "sub = val[['ImageId','Label']]\n",
    "\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
